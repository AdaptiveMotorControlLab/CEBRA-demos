{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4db2d9b",
   "metadata": {},
   "source": [
    "\n",
    "- this notebook will demo how to use CEBRA on the allen data (shown in Fig. 4, 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d60628",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b181f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib as jl\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import cebra.datasets\n",
    "from cebra import CEBRA\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "30a2f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e259af95",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "id": "2bacfd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35453f4d",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "- In this example, we load Ca (30 Hz) and Neuropixels (120Hz) recording from pseudomice (stacked neurons from multiple mice), recorded while the Natural Movie1 stimulus (30sec, 30Hz) was passively shown during 10 repeats. \n",
    "- Pre-defined CEBRA datasets used for the paper experiments include varied dataset with different \"cortex\", \"seed\" and \"num_neurons\".\n",
    "\n",
    "- Set \"cortex\" from [\"VISp\", \"VISpm\", \"VISam\", \"VISrl\", \"VISal\", \"VISl\"], \"seed\" from [111, 222, 333, 444, 555] and \"num_neurons\" from [10, 30, 50, 100, 200, 400, 600, 800, 900, 1000]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "61ae2bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex = 'VISp'\n",
    "seed=333\n",
    "num_neurons = 800\n",
    "\n",
    "ca_train = cebra.datasets.init(f'allen-movie-one-ca-{cortex}-{num_neurons}-train-10-{seed}')\n",
    "np_train = cebra.datasets.init(f'allen-movie-one-neuropixel-{cortex}-{num_neurons}-train-10-{seed}')\n",
    "joint_train = cebra.datasets.init(f'allen-movie-one-ca-neuropixel-{cortex}-{num_neurons}-train-10-{seed}')\n",
    "\n",
    "ca_test = cebra.datasets.init(f'allen-movie-one-ca-{cortex}-{num_neurons}-test-10-{seed}')\n",
    "np_test = cebra.datasets.init(f'allen-movie-one-neuropixel-{cortex}-{num_neurons}-test-10-{seed}')\n",
    "joint_test = cebra.datasets.init(f'allen-movie-one-ca-neuropixel-{cortex}-{num_neurons}-test-10-{seed}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "554de8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Neuropixels')"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax1= plt.subplot(1,2,1)\n",
    "ax1.imshow(ca_train.neural.cpu().numpy()[:900].T, aspect = 'auto', vmax = 1, vmin = 0, cmap ='gray_r')\n",
    "ax1.set_ylabel('# Neurons')\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_xticks(np.linspace(0,900, 4))\n",
    "ax1.set_xticklabels(np.linspace(0,30, 4))\n",
    "ax1.set_title('Ca spikes')\n",
    "ax2= plt.subplot(1,2,2)\n",
    "ax2.imshow(np_train.neural.cpu().numpy()[:3600].T, aspect = 'auto', vmax = 1, vmin = 0, cmap ='gray_r')\n",
    "ax2.set_ylabel('# Neurons')\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_xticks(np.linspace(0,3600, 4))\n",
    "ax2.set_xticklabels(np.linspace(0,30, 4))\n",
    "ax2.set_title('Neuropixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a799f",
   "metadata": {},
   "source": [
    "## Visualize DINO features of the video frames\n",
    "\n",
    "- CEBRA datasets include the video frames (Natural movie 1 from Allen Visual Coding) features extracted from a vision transformer model, DINO(https://arxiv.org/abs/2104.14294).\n",
    "- Here we visualize DINO features using 2D tSNE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "811af1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/cebra/anaconda3/envs/nlb/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/data/cebra/anaconda3/envs/nlb/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-43.977273559570314,\n",
       " 50.246514892578126,\n",
       " -47.49126300811768,\n",
       " 57.91667423248291)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dino_tsne = TSNE(n_components = 2)\n",
    "dino_tsne_viz = dino_tsne.fit_transform(ca_train.index[:900,:])\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "plt.scatter(dino_tsne_viz[:,0], dino_tsne_viz[:,1], cmap = 'magma', c = np.arange(900))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a37d8",
   "metadata": {},
   "source": [
    "## Train CEBRA models (Ca, Neuropixel, 1 frame window) using DINO features as behavior labels\n",
    "\n",
    "- We train CEBRA-Behavior models using the DINO video frames features as behavior labels on Ca recording, ephys recording.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f62816d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions to define CEBRA solvers\n",
    "\n",
    "def single_session_solver(data_loader, **kwargs):\n",
    "    \"\"\"Train a single session CEBRA model.\"\"\"\n",
    "    norm = True\n",
    "    if kwargs['distance'] == 'euclidean':\n",
    "        norm = False\n",
    "    data_loader.to(kwargs['device'])\n",
    "    model = cebra.models.init(kwargs['model_architecture'], data_loader.dataset.input_dimension,\n",
    "                              kwargs['num_hidden_units'],\n",
    "                              kwargs['output_dimension'], norm).to(kwargs['device'])\n",
    "    data_loader.dataset.configure_for(model)\n",
    "    if kwargs['distance'] == 'euclidean':\n",
    "        criterion = cebra.models.InfoMSE(temperature=kwargs['temperature'])\n",
    "    elif kwargs['distance'] == 'cosine':        \n",
    "        criterion = cebra.models.InfoNCE(temperature=kwargs['temperature'])\n",
    "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(), criterion.parameters()), lr=kwargs['learning_rate'])\n",
    "    return cebra.solver.SingleSessionSolver(model=model,\n",
    "                                            criterion=criterion,\n",
    "                                            optimizer=optimizer,\n",
    "                                            tqdm_on=kwargs['verbose'])\n",
    "\n",
    "def multi_session_solver(data_loader, **kwargs):\n",
    "    norm = True\n",
    "    if kwargs['distance'] == 'euclidean':\n",
    "        norm = False\n",
    "    for dataset in data_loader.dataset.iter_sessions():\n",
    "        dataset.to(kwargs['device'])\n",
    "        \n",
    "    model = torch.nn.ModuleList([\n",
    "        cebra.models.init(m, dataset.input_dimension,\n",
    "                          kwargs['num_hidden_units'], kwargs['output_dimension'], norm)\n",
    "        for dataset, m in zip(data_loader.dataset.iter_sessions(), kwargs['model_architecture'])\n",
    "    ]).to(kwargs['device'])\n",
    "    \n",
    "    for m in model:\n",
    "        m.to(kwargs['device'])\n",
    "    for n, dataset in enumerate(data_loader.dataset.iter_sessions()):\n",
    "        dataset.configure_for(model[n])\n",
    "    if kwargs['distance'] == 'euclidean':\n",
    "        criterion = cebra.models.InfoMSE(temperature=kwargs['temperature'])\n",
    "    elif kwargs['distance'] == 'cosine':        \n",
    "        criterion = cebra.models.InfoNCE(temperature=kwargs['temperature'])\n",
    "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(), criterion.parameters()), lr=kwargs['learning_rate'])\n",
    "    return cebra.solver.MultiSessionSolver(model=model,\n",
    "                                           criterion=criterion,\n",
    "                                           optimizer=optimizer,\n",
    "                                           tqdm_on=kwargs['verbose'])\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_emissions(model, dataset):\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    model.to(device)\n",
    "    dataset.configure_for(model)\n",
    "    return model(dataset[torch.arange(len(dataset))].to(device)).cpu().numpy()\n",
    "\n",
    "def _compute_emissions_single(solver, dataset):\n",
    "    return get_emissions(solver.model, dataset)\n",
    "\n",
    "def _compute_emissions_multi(solver, dataset):\n",
    "\n",
    "    return {\n",
    "        i :\n",
    "            get_emissions(model, session)\n",
    "            for i, (model, session) in enumerate(zip(solver.model, dataset.iter_sessions()))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7fcc36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7e889159",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_loader = cebra.data.ContinuousDataLoader(ca_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset =1)\n",
    "np_loader = cebra.data.ContinuousDataLoader(np_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f99cb1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_ca = single_session_solver(data_loader = ca_loader, model_architecture = 'offset1-model', \n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n",
    "\n",
    "cebra_np = single_session_solver(data_loader = np_loader, model_architecture = 'resample1-model', \n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8fba18f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.0017 neg:  5.2798 total:  5.2781 temperature:  1.0000: 100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [02:04<00:00, 80.07it/s]\n"
     ]
    }
   ],
   "source": [
    "cebra_ca.fit(ca_loader)\n",
    "cebra_ca_emb = _compute_emissions_single(cebra_ca, ca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "df9dcaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.0001 neg:  5.2804 total:  5.2805 temperature:  1.0000: 100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [02:45<00:00, 60.49it/s]\n"
     ]
    }
   ],
   "source": [
    "cebra_np.fit(np_loader)\n",
    "cebra_np_emb = _compute_emissions_single(cebra_np, np_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f30ee8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.21698331236839294,\n",
       " 0.21514176726341247,\n",
       " -0.24505507126450538,\n",
       " 0.219160146266222)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (12,5))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.set_title('Ca')\n",
    "ax1.scatter(cebra_ca_emb[:,0], cebra_ca_emb[:,1], cmap = 'magma', c = np.tile(np.arange(900),9), s=1)\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.set_title('Neuropixel')\n",
    "ax2.scatter(cebra_np_emb[:,0], cebra_np_emb[:,1], cmap = 'magma', c = np.tile(np.repeat(np.arange(900),4),9), s=1)\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c055ea5",
   "metadata": {},
   "source": [
    "## Train CEBRA models (Ca, Neuropixel joint training, 1 frame window) using DINO features as behavior labels\n",
    "\n",
    "- We use multisession-CEBRA to jointly train Ca and ephys recording, which generates consistent embeddings across the two recording modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "bec34104",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_loader = cebra.data.ContinuousMultiSessionDataLoader(joint_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f068d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_joint = multi_session_solver(data_loader = joint_loader, model_architecture = ['offset1-model', 'resample1-model'], \n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1baed33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.0009 neg:  5.9742 total:  5.9751 temperature:  1.0000: 100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [15:31<00:00, 10.73it/s]\n"
     ]
    }
   ],
   "source": [
    "cebra_joint.fit(joint_loader)\n",
    "cebra_joint_embs = _compute_emissions_multi(cebra_joint, joint_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6a81c6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.19728029146790504,\n",
       " 0.15147076919674873,\n",
       " -0.1323668047785759,\n",
       " 0.13234753757715226)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (12,5))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.set_title('Ca, jointly trained')\n",
    "ax1.scatter(cebra_joint_embs[0][:,0], cebra_joint_embs[0][:,1], cmap = 'magma', c = np.tile(np.arange(900),9), s=1)\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.set_title('Neuropixel, jointly trained')\n",
    "ax2.scatter(cebra_joint_embs[1][:,0], cebra_joint_embs[1][:,1], cmap = 'magma', c = np.tile(np.repeat(np.arange(900),4),9), s=1)\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e82d8f",
   "metadata": {},
   "source": [
    "## Decoding movie frame IDs (1 frame window)\n",
    "\n",
    "- We decode frame IDs (0-900, 30Hz, 30s movie) using CEBRA trained on Neuropixels only, jointly trained CEBRA and mean neural population activity of 1 frame window as a baseline. \n",
    "- We use kNN decoder for CEBRA embeddings and kNN & naive Bayes model for baseline decoders. \n",
    "- We use the 1-8th repeat as the train set, 9th repeat as the valid set, and the last 10th repeat as test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c9cc574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allen_frame_id_decode(train_fs, train_labels, test_fs, test_labels, modality = 'neuropixel', decoder = 'knn'):\n",
    "    \n",
    "    if modality == 'neuropixel':\n",
    "        FACTOR = 4\n",
    "    elif modality == 'ca':\n",
    "        FACTOR = 1\n",
    "    \n",
    "    time_window = 1\n",
    "    \n",
    "    def feature_for_one_frame(feature):\n",
    "        if isinstance(feature, torch.Tensor):\n",
    "            feature = feature.cpu().numpy()\n",
    "        return feature.reshape(-1,FACTOR,feature.shape[-1]).mean(axis = 1)\n",
    "    \n",
    "    train_fs = feature_for_one_frame(train_fs)\n",
    "    test_fs = feature_for_one_frame(test_fs)\n",
    "    \n",
    "    \n",
    "    if train_fs is None or test_fs is None:\n",
    "        return [None], [None], None\n",
    "    if decoder == 'knn':\n",
    "        params = np.power(np.linspace(1, 10, 5, dtype=int), 2)\n",
    "    elif decoder == 'bayes':\n",
    "        params = np.logspace(-9, 3, 5)\n",
    "    else:\n",
    "        raise ValueError('Choose decoder between knn or bayes')\n",
    "    errs = []\n",
    "\n",
    "    for n in params:\n",
    "        if decoder == 'knn':\n",
    "            train_decoder = KNeighborsClassifier(n_neighbors=n,\n",
    "                                                     metric='cosine')\n",
    "        elif decoder == 'bayes':\n",
    "            train_decoder = GaussianNB(var_smoothing = n)\n",
    "        train_valid_idx = int(len(train_fs)/9*8)\n",
    "        train_decoder.fit(train_fs[:train_valid_idx], train_labels[:train_valid_idx])\n",
    "        pred = train_decoder.predict(train_fs[train_valid_idx:])\n",
    "        err = train_labels[train_valid_idx:] - pred\n",
    "        errs.append(abs(err).sum())\n",
    "    \n",
    "    if decoder == 'knn':\n",
    "        test_decoder = KNeighborsClassifier(n_neighbors=params[np.argmin(errs)],\n",
    "                                                     metric='cosine')\n",
    "    elif decoder == 'bayes':\n",
    "        test_decoder = GaussianNB(var_smoothing = params[np.argmin(errs)])\n",
    "\n",
    "    test_decoder.fit(train_fs, train_labels)\n",
    "    pred = test_decoder.predict(test_fs)\n",
    "    frame_errors = pred - test_labels\n",
    "\n",
    "    def _quantize_acc(frame_diff, time_window=1):\n",
    "\n",
    "        true = (abs(frame_diff) < (time_window * 30)).sum()\n",
    "\n",
    "        return true / len(frame_diff) * 100\n",
    "\n",
    "    quantized_acc = _quantize_acc(frame_errors, time_window)\n",
    "\n",
    "    return pred, frame_errors, quantized_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7f8de886",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_joint_test = _compute_emissions_multi(cebra_joint, joint_test)\n",
    "cebra_np_test = _compute_emissions_single(cebra_np, np_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "035cc859",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_loader_1frame = cebra.data.ContinuousDataLoader(ca_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset =1)\n",
    "np_loader_1frame = cebra.data.ContinuousDataLoader(np_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset = 1)\n",
    "\n",
    "cebra_ca_1frame = single_session_solver(data_loader = ca_loader, model_architecture = 'offset1-model', \n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n",
    "\n",
    "cebra_np_1frame = single_session_solver(data_loader = np_loader, model_architecture = 'resample1-model', \n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n",
    "\n",
    "joint_loader_1frame = cebra.data.ContinuousMultiSessionDataLoader(joint_train, num_steps = train_steps, batch_size = 512, conditional = 'time_delta', time_offset=1)\n",
    "cebra_joint_1frame = multi_session_solver(data_loader = joint_loader, model_architecture = ['offset1-model', 'resample1-model'], \n",
    "                 distance = 'cosine', num_hidden_units = 128, output_dimension = 128,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "451aa8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn, errs_knn, acc_knn =allen_frame_id_decode(np_train.neural, np.tile(np.arange(900), 9),\n",
    "                     np_test.neural, np.arange(900), modality = 'neuropixel', decoder = 'knn')\n",
    "\n",
    "pred_bayes, errs_bayes, acc_bayes=allen_frame_id_decode(np_train.neural, np.tile(np.arange(900), 9),\n",
    "                     np_test.neural, np.arange(900), modality = 'neuropixel', decoder = 'bayes')\n",
    "\n",
    "pred_cebra, errs_cebra ,acc_cebra = allen_frame_id_decode(cebra_np_emb, np.tile(np.arange(900), 9), cebra_np_test, np.arange(900), modality = 'neuropixel', decoder = 'knn')\n",
    "\n",
    "pred_joint_cebra, errs_joint_cebra, acc_joint_cebra = allen_frame_id_decode(cebra_joint_embs[1], np.tile(np.arange(900), 9), cebra_joint_test[1], np.arange(900),modality = 'neuropixel', decoder = 'knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8e45cd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN baseline: 55.56%\n",
      "Bayes baseline: 67.67%\n",
      "CEBRA Neuropixel: 81.89%\n",
      "joint CEBRA Neuropixel: 89.00%\n"
     ]
    }
   ],
   "source": [
    "print(f'kNN baseline: {acc_knn:.2f}%')\n",
    "print(f'Bayes baseline: {acc_bayes:.2f}%')\n",
    "print(f'CEBRA Neuropixel: {acc_cebra:.2f}%')\n",
    "print(f'joint CEBRA Neuropixel: {acc_joint_cebra:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5ebd9",
   "metadata": {},
   "source": [
    "## Consistency across different visual cortical areas\n",
    "\n",
    "- We train jointly CEBRA-Behavior models using Ca and Neuropixels recordings from different visual cortical areas and compute linear consistencies between the cortical areas. We can observe that intra-area consistency is higher than inter-area consistencies. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "8ae74a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex1 = 'VISp'\n",
    "cortex2 = 'VISrl'\n",
    "\n",
    "cortex1=cebra.datasets.init(f\"allen-movie-one-ca-neuropixel-{cortex1}-disjoint-0-400-train-10-{seed}\")\n",
    "cortex2=cebra.datasets.init(f\"allen-movie-one-ca-neuropixel-{cortex2}-disjoint-0-400-train-10-{seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3501b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex1_loader = cebra.data.ContinuousMultiSessionDataLoader(cortex1, num_steps = 1000, batch_size = 512, conditional = 'time_delta', time_offset=10)\n",
    "cebra_cortex1 = multi_session_solver(data_loader = cortex1_loader, model_architecture = ['offset10-model', 'resample-model'], \n",
    "                 distance = 'cosine', num_hidden_units = 32, output_dimension = 32,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n",
    "\n",
    "cortex2_loader = cebra.data.ContinuousMultiSessionDataLoader(cortex2, num_steps = 1000, batch_size = 512, conditional = 'time_delta', time_offset=10)\n",
    "cebra_cortex2 = multi_session_solver(data_loader = cortex2_loader, model_architecture = ['offset10-model', 'resample-model'], \n",
    "                 distance = 'cosine', num_hidden_units = 32, output_dimension = 32,\n",
    "                verbose = True, device = DEVICE, temperature = 1, learning_rate = 3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "6fe1133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.0295 neg:  6.0520 total:  6.0815 temperature:  1.0000: 100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:21<00:00,  7.05it/s]\n",
      "pos:  0.0908 neg:  6.1152 total:  6.2060 temperature:  1.0000: 100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:18<00:00,  7.20it/s]\n"
     ]
    }
   ],
   "source": [
    "cebra_cortex1.fit(cortex1_loader)\n",
    "cebra_cortex2.fit(cortex2_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "8148adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_cortex1_embs = _compute_emissions_multi(cebra_cortex1, cortex1)\n",
    "cebra_cortex2_embs = _compute_emissions_multi(cebra_cortex2, cortex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "ad3c236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A helper function to compute linear consistency\n",
    "def consistency(feature1, feature2):\n",
    "    if len(feature1) == 32400:\n",
    "        feature1 = feature1.reshape(-1, 4, feature1.shape[-1]).mean(axis=1)\n",
    "    if len(feature2) == 32400:\n",
    "        feature2 = feature2.reshape(-1, 4, feature2.shape[-1]).mean(axis=1)\n",
    "    def _linear_fit(a,b):\n",
    "        lin_model = LinearRegression()\n",
    "        lin_model.fit(a, b)\n",
    "        return lin_model.score(a, b)\n",
    "    return _linear_fit(feature1, feature2), _linear_fit(feature2, feature1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5ce5fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_cortices = consistency(cebra_cortex1_embs[0], cebra_cortex1_embs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "dde607f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_cortices = []\n",
    "for cortex1_emb in cebra_cortex1_embs.values():\n",
    "    for cortex2_emb in cebra_cortex2_embs.values():\n",
    "        inter_cortices.extend(consistency(cortex1_emb, cortex2_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "0e5bec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intra-area: 0.90\n",
      "Inter-area: 0.60\n"
     ]
    }
   ],
   "source": [
    "print(f\"Intra-area: {np.mean(intra_cortices):.2f}\")\n",
    "print(f\"Inter-area: {np.mean(inter_cortices):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ed03f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python",
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
