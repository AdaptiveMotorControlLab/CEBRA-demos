{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2646203e",
   "metadata": {},
   "source": [
    "- this notebook will demo how to use CEBRA, piVAE, tSNE and UMAP on synthetic datasets.\n",
    "\n",
    "- Mac pre-M1, *Windows, and Ubuntu users can skip to cell 2.\n",
    "- *This has not been tested on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad682de4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Attention: M1 chip users ONLY: \n",
    "# TF is a dependency of piVAE, which is used in this demo. \n",
    "# It requires a few extra steps that are addressed in this cell; in short, please run this once.\n",
    "# See also: https://developer.apple.com/metal/tensorflow-plugin/ if any issues.\n",
    "\n",
    "!pip uninstall -y tensorflow-deps tensorflow-macos tensorflow-metal keras\n",
    "\n",
    "!conda install pytorch torchvision torchaudio -c pytorch\n",
    "!pip install --upgrade --force-reinstall scikit-learn\n",
    "\n",
    "!conda install -c apple -y tensorflow-deps==2.5.0 --force-reinstall\n",
    "!python -m pip install tensorflow-macos\n",
    "!python -m pip install tensorflow-metal"
   ]
  },
    "!pip install 'cebra[datasets,demos]'"
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d77499",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import packages:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib as jl\n",
    "import sklearn.linear_model\n",
    "import openTSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3480fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwmathis/miniforge3/envs/cebra_m1/lib/python3.9/site-packages/numba/cpython/hashing.py:524: UserWarning: FNV hashing is not implemented in Numba. See PEP 456 https://www.python.org/dev/peps/pep-0456/ for rationale over not using FNV. Numba will continue to work, but hashes for built in types will be computed using siphash24. This will permit e.g. dictionaries to continue to behave as expected, however anything relying on the value of the hash opposed to hash as a derived property is likely to not work as expected.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8436f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import CEBRA:\n",
    "from cebra import CEBRA\n",
    "from cebra.datasets import get_datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c013dff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import piVAE:\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../third_party')\n",
    "import pivae.pivae_code.pi_vae as pivae\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66213c",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d1b0b",
   "metadata": {},
   "source": [
    "### Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0dc046c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.411717481214122, 9.427972850408525, -4.042572592877058, 4.03572573445655)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = jl.load(get_datapath('synthetic/continuous_label_poisson.jl'))\n",
    "plt.scatter(data['z'][:, 0], data['z'][:, 1], c=data['u'], s=1, cmap='cool')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270e0ca9",
   "metadata": {},
   "source": [
    "### Define the reconstruction score we use for all methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c06714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_score(x, y):\n",
    "\n",
    "    def _linear_fitting(x, y):\n",
    "        lin_model = sklearn.linear_model.LinearRegression()\n",
    "        lin_model.fit(x, y)\n",
    "        return lin_model.score(x, y), lin_model.predict(x)\n",
    "\n",
    "    return _linear_fitting(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35789656",
   "metadata": {},
   "source": [
    "# CEBRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9a524",
   "metadata": {},
   "source": [
    "- Define & fit a ðŸ¦“ <font color='blue'>C</font><font color='MediumSlateBlue'>E</font><font color='BlueViolet'>B</font><font color='MediumVioletRed'>R</font><font color='red'>A</font>  model:\n",
    "- For a quick CPU run-time demo, you can drop `max_iterations` to 500; otherwise set to 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0266553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd837aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_model = CEBRA(\n",
    "    model_architecture=\"offset1-model-mse\",\n",
    "    batch_size=512,\n",
    "    learning_rate=1e-4,\n",
    "    max_iterations=max_iterations,\n",
    "    delta=0.1,\n",
    "    conditional='delta',\n",
    "    output_dimension=2,\n",
    "    distance='euclidean',\n",
    "    device=\"cuda_if_available\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e744923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_continuous_index\n",
      "_discrete_index\n",
      "_seed\n",
      "_seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.6078 neg:  4.5545 total:  5.1623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [01:50<00:00, 45.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CEBRA(batch_size=512, conditional=&#x27;delta&#x27;, delta=0.1, distance=&#x27;euclidean&#x27;,\n",
       "      learning_rate=0.0001, max_iterations=5000,\n",
       "      model_architecture=&#x27;offset1-model-mse&#x27;, output_dimension=2, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CEBRA</label><div class=\"sk-toggleable__content\"><pre>CEBRA(batch_size=512, conditional=&#x27;delta&#x27;, delta=0.1, distance=&#x27;euclidean&#x27;,\n",
       "      learning_rate=0.0001, max_iterations=5000,\n",
       "      model_architecture=&#x27;offset1-model-mse&#x27;, output_dimension=2, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CEBRA(batch_size=512, conditional='delta', delta=0.1, distance='euclidean',\n",
       "      learning_rate=0.0001, max_iterations=5000,\n",
       "      model_architecture='offset1-model-mse', output_dimension=2, verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cebra_model.fit(data['x'][:12000], data['u'][:12000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ccba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear reconstruction score: 0.9182325140113027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.0815959811210631,\n",
       " 8.637835347652436,\n",
       " -2.9030434846878053,\n",
       " 2.9840209245681764)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cebra_output = cebra_model.transform(data['x'])\n",
    "cebra_score, transformed_cebra_z = reconstruction_score(cebra_output,\n",
    "                                                        data['z'][:, :2])\n",
    "print(f\"linear reconstruction score: {cebra_score}\")\n",
    "plt.scatter(transformed_cebra_z[:, 0],\n",
    "            transformed_cebra_z[:, 1],\n",
    "            c=data['u'],\n",
    "            s=1,\n",
    "            cmap='cool')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0582f1",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77aa578",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_model = openTSNE.TSNE(perplexity=84,\n",
    "                           n_components=2,\n",
    "                           initialization='pca',\n",
    "                           random_state=None,\n",
    "                           metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c895b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_model.fit(data['x'])\n",
    "tsne_output = tsne_model.fit(data['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eb1d80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear reconstruction score: 0.7932575825931458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.38784403902211856,\n",
       " 7.009045915002804,\n",
       " -2.7633283196331018,\n",
       " 2.5604785068064775)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsne_score, transformed_tsne_z = reconstruction_score(tsne_output,\n",
    "                                                      data['z'][:, :2])\n",
    "print(f\"linear reconstruction score: {tsne_score}\")\n",
    "plt.scatter(transformed_tsne_z[:, 0],\n",
    "            transformed_tsne_z[:, 1],\n",
    "            c=data['u'],\n",
    "            s=1,\n",
    "            cmap='cool')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78bb3e7",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3871078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "umap_model = umap.UMAP(n_neighbors=68,\n",
    "                       min_dist=0.2475,\n",
    "                       n_components=2,\n",
    "                       random_state=None,\n",
    "                       metric='euclidean')\n",
    "umap_output = umap_model.fit_transform(data['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b942df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear reconstruction score: 0.8285673979402988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.4230464577674866, 6.97549067735672, -2.575450968742371, 2.7685633420944216)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "umap_score, transformed_umap_z = reconstruction_score(umap_output,\n",
    "                                                      data['z'][:, :2])\n",
    "print(f\"linear reconstruction score: {umap_score}\")\n",
    "plt.scatter(transformed_umap_z[:, 0],\n",
    "            transformed_umap_z[:, 1],\n",
    "            c=data['u'],\n",
    "            s=1,\n",
    "            cmap='cool')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b084f2",
   "metadata": {},
   "source": [
    "# piVAE\n",
    "\n",
    "The dataset parsing, model configuration and training are all adapted from https://github.com/zhd96/pi-vae/blob/main/examples/pi-vae_simulated_data_continuous_label.ipynb\n",
    "- piVAE has a long run time. We store checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5b028b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 40 samples\n"
     ]
    }
   ],
   "source": [
    "u_true = data['u']\n",
    "z_true = data['z']\n",
    "x_true = data['x']\n",
    "x_all = x_true.reshape(50, 300, -1)\n",
    "u_all = u_true.reshape(50, 300, -1)\n",
    "\n",
    "x_train = x_all[:40]\n",
    "u_train = u_all[:40]\n",
    "x_valid = x_all[40:]\n",
    "u_valid = u_all[40:]\n",
    "print(f'Train set has {len(x_train)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb5a7368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 19:46:30.664168: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-20 19:46:30.664281: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " encoder (Functional)           [(None, 2),          20228       ['input_1[0][0]',                \n",
      "                                 (None, 2),                       'input_3[0][0]']                \n",
      "                                 (None, 2),                                                       \n",
      "                                 (None, 2),                                                       \n",
      "                                 (None, 2),                                                       \n",
      "                                 (None, 2),                                                       \n",
      "                                 (None, 2)]                                                       \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 100)          21269       ['encoder[0][2]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 2)           0           ['encoder[0][0]',                \n",
      " )                                                                'encoder[0][5]']                \n",
      "                                                                                                  \n",
      " tf.math.square (TFOpLambda)    (None, 2)            0           ['tf.math.subtract_2[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.exp (TFOpLambda)       (None, 2)            0           ['encoder[0][1]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 2)           0           ['encoder[0][1]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 2)           0           ['tf.math.square[0][0]',         \n",
      " mbda)                                                            'tf.math.exp[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.exp_1 (TFOpLambda)     (None, 2)            0           ['encoder[0][6]']                \n",
      "                                                                                                  \n",
      " tf.math.log (TFOpLambda)       (None, 100)          0           ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 2)           0           ['tf.__operators__.add[0][0]',   \n",
      " )                                                                'encoder[0][6]']                \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 2)            0           ['tf.__operators__.add_1[0][0]', \n",
      "                                                                  'tf.math.exp_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 100)          0           ['input_1[0][0]',                \n",
      "                                                                  'tf.math.log[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLambda  (None, 2)           0           ['tf.math.subtract_1[0][0]',     \n",
      " )                                                                'tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 100)          0           ['decoder[0][0]',                \n",
      "                                                                  'tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None,)             0           ['tf.math.subtract_3[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None,)             0           ['tf.math.subtract[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_1[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None,)             0           ['tf.math.reduce_sum[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.__operators__.add_2[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 41,497\n",
      "Trainable params: 41,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwmathis/miniforge3/envs/cebra_m1/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "vae = pivae.vae_mdl(dim_x=x_all[0].shape[-1],\n",
    "                    dim_z=2,\n",
    "                    dim_u=u_all[0].shape[-1],\n",
    "                    gen_nodes=60,\n",
    "                    n_blk=2,\n",
    "                    mdl='poisson',\n",
    "                    disc=False,\n",
    "                    learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcc5dce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/4w_vk2wn10xb_xj2fm7d6vqc0000gn/T/ipykernel_17311/1414530926.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  s_n = vae.fit_generator(pivae.custom_data_generator(x_train, u_train),\n",
      "2022-09-20 19:46:31.009258: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-09-20 19:46:31.716471: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-20 19:46:33.174729: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model_chk_path = 'synthetic_pivae.h5'\n",
    "mcp = ModelCheckpoint(model_chk_path,\n",
    "                      monitor=\"val_loss\",\n",
    "                      save_best_only=True,\n",
    "                      save_weights_only=True)\n",
    "s_n = vae.fit_generator(pivae.custom_data_generator(x_train, u_train),\n",
    "                        steps_per_epoch=len(x_train),\n",
    "                        epochs=100,\n",
    "                        verbose=0,\n",
    "                        validation_data=pivae.custom_data_generator(\n",
    "                            x_valid, u_valid),\n",
    "                        validation_steps=len(x_valid),\n",
    "                        callbacks=[mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d6e7443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/4w_vk2wn10xb_xj2fm7d6vqc0000gn/T/ipykernel_17311/323301550.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  outputs = vae.predict_generator(pivae.custom_data_generator(x_all, u_all),\n",
      "2022-09-20 19:47:56.368218: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "vae.load_weights(model_chk_path)\n",
    "outputs = vae.predict_generator(pivae.custom_data_generator(x_all, u_all),\n",
    "                                steps=len(x_all))\n",
    "#post_mean, post_log_var, z_sample,fire_rate, lam_mean, lam_log_var, z_mean, z_log_var\n",
    "z_post = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49d9f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear reconstruction score: 0.8170253307283855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.922655415534973, 7.055900406837464, -2.461803549528122, 1.9950003564357757)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pivae_score, transformed_pivae_z = reconstruction_score(z_post,\n",
    "                                                        data['z'][:, :2])\n",
    "print(f\"linear reconstruction score: {pivae_score}\")\n",
    "plt.scatter(transformed_pivae_z[:, 0],\n",
    "            transformed_pivae_z[:, 1],\n",
    "            c=data['u'],\n",
    "            s=1,\n",
    "            cmap='cool')\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
